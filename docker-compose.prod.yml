version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: seo-postgres-prod
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./init_schema.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    ports:
      - "127.0.0.1:5432:5432"
    networks:
      - database
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  redis:
    image: redis:7-alpine
    container_name: seo-redis-prod
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 4gb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_prod_data:/data
    ports:
      - "127.0.0.1:6379:6379"
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: seo-rabbitmq-prod
    hostname: seo-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: /
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 2048MiB
      RABBITMQ_DISK_FREE_LIMIT: 2GB
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "-rabbit consumer_timeout 86400000"
    volumes:
      - rabbitmq_prod_data:/var/lib/rabbitmq
    ports:
      - "127.0.0.1:5672:5672"
      - "127.0.0.1:15672:15672"
    networks:
      - backend
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

  audit-service:
    build:
      context: .
      dockerfile: audit_service/Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/audit-service:${VERSION:-latest}
    container_name: seo-audit-service-prod
    command: gunicorn audit_service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8001 --timeout 120 --graceful-timeout 30 --max-requests 1000 --max-requests-jitter 50
    environment:
      SERVICE_NAME: audit-service
      SERVICE_PORT: 8001
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    ports:
      - "127.0.0.1:8001:8001"
    volumes:
      - ./logs:/app/logs
    networks:
      - frontend
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  semantic-service:
    build:
      context: .
      dockerfile: semantic_service/Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/semantic-service:${VERSION:-latest}
    container_name: seo-semantic-service-prod
    command: gunicorn semantic_service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8002 --timeout 300 --graceful-timeout 30 --max-requests 1000 --max-requests-jitter 50
    environment:
      SERVICE_NAME: semantic-service
      SERVICE_PORT: 8002
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:8002:8002"
    volumes:
      - ./logs:/app/logs
    networks:
      - frontend
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 3G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  reporting-service:
    build:
      context: .
      dockerfile: reporting_service/Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/reporting-service:${VERSION:-latest}
    container_name: seo-reporting-service-prod
    command: gunicorn reporting_service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8003 --timeout 300 --graceful-timeout 30 --max-requests 1000 --max-requests-jitter 50
    environment:
      SERVICE_NAME: reporting-service
      SERVICE_PORT: 8003
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:8003:8003"
    volumes:
      - ./logs:/app/logs
      - ./reports:/app/reports
    networks:
      - frontend
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  management-service:
    build:
      context: .
      dockerfile: management_service/Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/management-service:${VERSION:-latest}
    container_name: seo-management-service-prod
    command: gunicorn management_service.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8004 --timeout 120 --graceful-timeout 30 --max-requests 1000 --max-requests-jitter 50
    environment:
      SERVICE_NAME: management-service
      SERVICE_PORT: 8004
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:8004:8004"
    volumes:
      - ./logs:/app/logs
    networks:
      - frontend
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  client-api-gateway:
    build:
      context: .
      dockerfile: client_api_gateway/Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/client-api-gateway:${VERSION:-latest}
    container_name: seo-client-api-gateway-prod
    command: gunicorn client_api_gateway.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8005 --timeout 120 --graceful-timeout 30 --max-requests 1000 --max-requests-jitter 50
    environment:
      SERVICE_NAME: client-api-gateway
      SERVICE_PORT: 8005
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:8005:8005"
    volumes:
      - ./logs:/app/logs
    networks:
      - frontend
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  celery-worker-audit:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/celery-worker:${VERSION:-latest}
    container_name: seo-celery-worker-audit-prod
    command: celery -A celery_config worker --queues=audit_crawl,public_audit_queue --concurrency=4 --loglevel=info --max-tasks-per-child=50 --time-limit=3600 --soft-time-limit=3300
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      WORKER_TYPE: audit
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    networks:
      - backend
      - database
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '2'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  celery-worker-semantic:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/celery-worker:${VERSION:-latest}
    container_name: seo-celery-worker-semantic-prod
    command: celery -A celery_config worker --queues=semantic_analysis,llm_generation --concurrency=8 --loglevel=info --max-tasks-per-child=100 --time-limit=7200 --soft-time-limit=7000
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      WORKER_TYPE: semantic
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    networks:
      - backend
      - database
    restart: always
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 6G
        reservations:
          cpus: '2'
          memory: 3G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  celery-worker-reporting:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/celery-worker:${VERSION:-latest}
    container_name: seo-celery-worker-reporting-prod
    command: celery -A celery_config worker --queues=reporting_export,gsc_sync,ga4_sync,yandex_sync --concurrency=4 --loglevel=info --max-tasks-per-child=100 --time-limit=3600 --soft-time-limit=3300
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      WORKER_TYPE: reporting
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
      - ./reports:/app/reports
    networks:
      - backend
      - database
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 3G
        reservations:
          cpus: '1'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/celery-beat:${VERSION:-latest}
    container_name: seo-celery-beat-prod
    command: celery -A celery_config beat --loglevel=info
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
      ENVIRONMENT: production
      LOG_LEVEL: INFO
      PYTHONUNBUFFERED: 1
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    networks:
      - backend
      - database
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

  flower:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ENVIRONMENT: production
    image: seo-platform/flower:${VERSION:-latest}
    container_name: seo-flower-prod
    command: celery -A celery_config flower --port=5555 --broker=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672// --basic_auth=${FLOWER_USER}:${FLOWER_PASSWORD}
    environment:
      FLOWER_BASIC_AUTH: ${FLOWER_USER}:${FLOWER_PASSWORD}
      FLOWER_PORT: 5555
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672//
    env_file:
      - .env.production
    depends_on:
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    ports:
      - "127.0.0.1:5555:5555"
    networks:
      - frontend
      - backend
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

  nginx:
    image: nginx:alpine
    container_name: seo-nginx-prod
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./nginx/logs:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - audit-service
      - semantic-service
      - reporting-service
      - management-service
      - client-api-gateway
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '1'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    security_opt:
      - no-new-privileges:true

  prometheus:
    image: prom/prometheus:latest
    container_name: seo-prometheus-prod
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=90d'
      - '--storage.tsdb.retention.size=50GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_prod_data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    networks:
      - backend
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

  grafana:
    image: grafana/grafana:latest
    container_name: seo-grafana-prod
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource,grafana-piechart-panel
      GF_SERVER_ROOT_URL: https://monitoring.seo-platform.com
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
    volumes:
      - grafana_prod_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "127.0.0.1:3000:3000"
    depends_on:
      - prometheus
    networks:
      - backend
      - frontend
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    security_opt:
      - no-new-privileges:true

volumes:
  postgres_prod_data:
    driver: local
  redis_prod_data:
    driver: local
  rabbitmq_prod_data:
    driver: local
  prometheus_prod_data:
    driver: local
  grafana_prod_data:
    driver: local

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
  database:
    driver: bridge
    internal: true
